{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imported the ncessary library that are needed\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import Word\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix,cohen_kappa_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the data -- removing the contractions, punctuations\n",
    "def clean_str(string):\n",
    "    string = re.sub(r\"\\'s\", \"\", string)\n",
    "    string = re.sub(r\"\\'ve\", \"\", string)\n",
    "    string = re.sub(r\"n\\'t\", \"\", string)\n",
    "    string = re.sub(r\"\\'re\", \"\", string)\n",
    "    string = re.sub(r\"\\'d\", \"\", string)\n",
    "    string = re.sub(r\"\\'ll\", \"\", string)\n",
    "    string = re.sub(r\",\", \"\", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \"\", string)\n",
    "    string = re.sub(r\"\\)\", \"\", string)\n",
    "    string = re.sub(r\"\\?\", \"\", string)\n",
    "    string = re.sub(r\"'\", \"\", string)\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"[0-9]\\w+|[0-9]\", \"\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv file and then preprocessing each news article\n",
    "data = pd.read_csv('C:/Users/Vijay/Desktop/code/code/dataset.csv',encoding = \"ISO-8859-1\")\n",
    "x = data['news'].tolist()\n",
    "y = data['type'].tolist()\n",
    "\n",
    "for index, value in enumerate(x):\n",
    "    x[index] = ' '.join([Word(word).lemmatize() for word in clean_str(value).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performed TF-IDF \n",
    "vect = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "X = vect.fit_transform(x)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of features extracted: 14788\n"
     ]
    }
   ],
   "source": [
    "print(\"no of features extracted:\", X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (1780, 14788)\n",
      "test size: (445, 14788)\n"
     ]
    }
   ],
   "source": [
    "# divided the dataset into test and train using test_train_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"train size:\", X_train.shape)\n",
    "print(\"test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traines the model and then tested on test data\n",
    "model = RandomForestClassifier(n_estimators=300, max_depth=150, n_jobs=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved the model for future reference \n",
    "joblib.dump(model, 'model.pkl')\n",
    "joblib.dump(vect, 'vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[110   0   3   1   1]\n",
      " [  2  67   2   0   1]\n",
      " [  3   0  73   0   0]\n",
      " [  0   0   0 102   0]\n",
      " [  2   1   0   2  75]]\n",
      "\n",
      "Kappa:  0.9489405645222979\n",
      "\n",
      "Accuracy:  0.9595505617977528\n"
     ]
    }
   ],
   "source": [
    "# calculated the confusion matrix, kappa score, accuracy score\n",
    "c_mat = confusion_matrix(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", c_mat)\n",
    "print(\"\\nKappa: \", kappa)\n",
    "print(\"\\nAccuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
